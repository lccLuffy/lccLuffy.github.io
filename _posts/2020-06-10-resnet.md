---
layout: post
permalink: /resnet/
title: "ResNet: Deep Residual Learning for Image Recognition"
date: 2020-06-10T16:44:58
lang: zh-CN
math: true
---

[Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) 一文提出了残差连接，并以此为 building block 构建了 ResNet，大大提高了网络深度，在多项计算机视觉任务中取得最佳成绩。

<!-- more -->

![Residual learning: a building block](https://static.lufficc.com/2020/06/10/8174b526087d6f62.png){.to-figure}

残差连接如上图所示，即映射 $H(x) = F(x) + x$。ResNet 能保持这么深并且不造成梯度消失，得益于残差连接。**即网络在向后连接的同时，保持对较浅层的引用，那么在梯度传播的时候，就会多一种选择：梯度可以来自函数 $F(x)$，也可以来自 $x$**。$H(x) = F(x) + x$ 是对 $H(x) = F(x)$ 的一种推广，$F(x)$ 能完成的目标函数，$F(x) + x$ 也可以，但多一种选择，多无限可能。

**网络结构结构决定一切。**
